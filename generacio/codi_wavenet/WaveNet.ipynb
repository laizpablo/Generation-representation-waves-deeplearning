{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wave Net Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa>=0.4.3 (from -r requirements.txt (line 1))\n",
      "  Downloading librosa-0.4.3.tar.gz (1.5MB)\n",
      "\u001b[K    100% |################################| 1.5MB 804kB/s \n",
      "\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): pep8>=1.7.0 in /opt/anaconda/lib/python2.7/site-packages (from -r requirements.txt (line 2))\n",
      "Requirement already satisfied (use --upgrade to upgrade): nose>=1.3.7 in /opt/anaconda/lib/python2.7/site-packages (from -r requirements.txt (line 3))\n",
      "Collecting audioread>=2.0.0 (from librosa>=0.4.3->-r requirements.txt (line 1))\n",
      "  Downloading audioread-2.1.4.tar.gz\n",
      "Requirement already satisfied (use --upgrade to upgrade): numpy>=1.8.0 in /opt/anaconda/lib/python2.7/site-packages (from librosa>=0.4.3->-r requirements.txt (line 1))\n",
      "Requirement already satisfied (use --upgrade to upgrade): scipy>=0.13.0 in /opt/anaconda/lib/python2.7/site-packages (from librosa>=0.4.3->-r requirements.txt (line 1))\n",
      "Requirement already satisfied (use --upgrade to upgrade): scikit-learn>=0.14.0 in /opt/anaconda/lib/python2.7/site-packages (from librosa>=0.4.3->-r requirements.txt (line 1))\n",
      "Requirement already satisfied (use --upgrade to upgrade): matplotlib>=1.4.3 in /opt/anaconda/lib/python2.7/site-packages (from librosa>=0.4.3->-r requirements.txt (line 1))\n",
      "Collecting joblib>=0.7.0 (from librosa>=0.4.3->-r requirements.txt (line 1))\n",
      "  Downloading joblib-0.10.3-py2.py3-none-any.whl (166kB)\n",
      "\u001b[K    100% |################################| 174kB 2.6MB/s \n",
      "\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): decorator>=3.0.0 in /opt/anaconda/lib/python2.7/site-packages (from librosa>=0.4.3->-r requirements.txt (line 1))\n",
      "Requirement already satisfied (use --upgrade to upgrade): six>=1.3 in /opt/anaconda/lib/python2.7/site-packages (from librosa>=0.4.3->-r requirements.txt (line 1))\n",
      "Collecting resampy>=0.1.0 (from librosa>=0.4.3->-r requirements.txt (line 1))\n",
      "  Downloading resampy-0.1.4.tar.gz (442kB)\n",
      "\u001b[K    100% |################################| 450kB 1.8MB/s \n",
      "\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): python-dateutil in /opt/anaconda/lib/python2.7/site-packages (from matplotlib>=1.4.3->librosa>=0.4.3->-r requirements.txt (line 1))\n",
      "Requirement already satisfied (use --upgrade to upgrade): pytz in /opt/anaconda/lib/python2.7/site-packages (from matplotlib>=1.4.3->librosa>=0.4.3->-r requirements.txt (line 1))\n",
      "Requirement already satisfied (use --upgrade to upgrade): cycler in /opt/anaconda/lib/python2.7/site-packages (from matplotlib>=1.4.3->librosa>=0.4.3->-r requirements.txt (line 1))\n",
      "Requirement already satisfied (use --upgrade to upgrade): pyparsing!=2.0.4,>=1.5.6 in /opt/anaconda/lib/python2.7/site-packages (from matplotlib>=1.4.3->librosa>=0.4.3->-r requirements.txt (line 1))\n",
      "Requirement already satisfied (use --upgrade to upgrade): Cython>=0.23 in /opt/anaconda/lib/python2.7/site-packages (from resampy>=0.1.0->librosa>=0.4.3->-r requirements.txt (line 1))\n",
      "Building wheels for collected packages: librosa, audioread, resampy\n",
      "  Running setup.py bdist_wheel for librosa ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/83/64/55/9a3e23c7b7c81fa24e65ac537192eaa91285644a42c999b81e\n",
      "  Running setup.py bdist_wheel for audioread ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/62/1b/49/0384c1e62978b50f516e813410d2d5f466a9a4fe520790f105\n",
      "  Running setup.py bdist_wheel for resampy ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/a4/64/9a/bb674db6afe6313c225007204444cde44766da4f2d6b5e6992\n",
      "Successfully built librosa audioread resampy\n",
      "Installing collected packages: audioread, joblib, resampy, librosa\n",
      "Successfully installed audioread-2.1.4 joblib-0.10.3 librosa-0.4.3 resampy-0.1.4\n",
      "\u001b[33mYou are using pip version 8.1.2, however version 9.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements_test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so.8.0 locally\n",
      "I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so.5 locally\n",
      "I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so.8.0 locally\n",
      "I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\n",
      "I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so.8.0 locally\n",
      "usage: train.py [-h] [--batch_size BATCH_SIZE] [--data_dir DATA_DIR]\n",
      "                [--store_metadata STORE_METADATA] [--logdir LOGDIR]\n",
      "                [--logdir_root LOGDIR_ROOT] [--restore_from RESTORE_FROM]\n",
      "                [--checkpoint_every CHECKPOINT_EVERY] [--num_steps NUM_STEPS]\n",
      "                [--learning_rate LEARNING_RATE]\n",
      "                [--wavenet_params WAVENET_PARAMS] [--sample_size SAMPLE_SIZE]\n",
      "                [--l2_regularization_strength L2_REGULARIZATION_STRENGTH]\n",
      "                [--silence_threshold SILENCE_THRESHOLD]\n",
      "                [--optimizer {rmsprop,adam,sgd}] [--momentum MOMENTUM]\n",
      "                [--histograms HISTOGRAMS]\n",
      "\n",
      "WaveNet example network\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --batch_size BATCH_SIZE\n",
      "                        How many wav files to process at once.\n",
      "  --data_dir DATA_DIR   The directory containing the VCTK corpus.\n",
      "  --store_metadata STORE_METADATA\n",
      "                        Whether to store advanced debugging information\n",
      "                        (execution time, memory consumption) for use with\n",
      "                        TensorBoard.\n",
      "  --logdir LOGDIR       Directory in which to store the logging information\n",
      "                        for TensorBoard. If the model already exists, it will\n",
      "                        restore the state and will continue training. Cannot\n",
      "                        use with --logdir_root and --restore_from.\n",
      "  --logdir_root LOGDIR_ROOT\n",
      "                        Root directory to place the logging output and\n",
      "                        generated model. These are stored under the dated\n",
      "                        subdirectory of --logdir_root. Cannot use with\n",
      "                        --logdir.\n",
      "  --restore_from RESTORE_FROM\n",
      "                        Directory in which to restore the model from. This\n",
      "                        creates the new model under the dated directory in\n",
      "                        --logdir_root. Cannot use with --logdir.\n",
      "  --checkpoint_every CHECKPOINT_EVERY\n",
      "                        How many steps to save each checkpoint after\n",
      "  --num_steps NUM_STEPS\n",
      "                        Number of training steps.\n",
      "  --learning_rate LEARNING_RATE\n",
      "                        Learning rate for training.\n",
      "  --wavenet_params WAVENET_PARAMS\n",
      "                        JSON file with the network parameters.\n",
      "  --sample_size SAMPLE_SIZE\n",
      "                        Concatenate and cut audio samples to this many\n",
      "                        samples.\n",
      "  --l2_regularization_strength L2_REGULARIZATION_STRENGTH\n",
      "                        Coefficient in the L2 regularization. Disabled by\n",
      "                        default\n",
      "  --silence_threshold SILENCE_THRESHOLD\n",
      "                        Volume threshold below which to trim the start and the\n",
      "                        end from the training set samples.\n",
      "  --optimizer {rmsprop,adam,sgd}\n",
      "                        Select the optimizer specified by this option.\n",
      "  --momentum MOMENTUM   Specify the momentum to be used by sgd or rmsprop\n",
      "                        optimizer. Ignored by the adam optimizer.\n",
      "  --histograms HISTOGRAMS\n",
      "                        Whether to store histogram summaries.\n"
     ]
    }
   ],
   "source": [
    "!python train.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenament"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so.8.0 locally\n",
      "I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so.5 locally\n",
      "I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so.8.0 locally\n",
      "I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\n",
      "I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so.8.0 locally\n",
      "Using default logdir: ./logdir/train/2016-12-18T22-30-18\n",
      "I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "I tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 0 with properties: \n",
      "name: GeForce GTX TITAN Black\n",
      "major: 3 minor: 5 memoryClockRate (GHz) 0.98\n",
      "pciBusID 0000:01:00.0\n",
      "Total memory: 5.93GiB\n",
      "Free memory: 5.42GiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_device.cc:972] DMA: 0 \n",
      "I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 0:   Y \n",
      "I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN Black, pci bus id: 0000:01:00.0)\n",
      "Trying to restore saved checkpoints from ./logdir/train/2016-12-18T22-30-18 ... No checkpoint found.\n",
      "E tensorflow/stream_executor/cuda/cuda_driver.cc:965] failed to allocate 4.00G (4294967296 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\n",
      "E tensorflow/stream_executor/cuda/cuda_driver.cc:965] failed to allocate 3.60G (3865470464 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\n",
      "E tensorflow/stream_executor/cuda/cuda_driver.cc:965] failed to allocate 3.24G (3478923264 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\n",
      "E tensorflow/stream_executor/cuda/cuda_driver.cc:965] failed to allocate 2.92G (3131030784 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\n",
      "step 0 - loss = 5.540768, (20.868 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2016-12-18T22-30-18 ... Done.\n",
      "step 1 - loss = 5.531959, (3.272 sec/step)\n",
      "step 2 - loss = 5.522453, (3.243 sec/step)\n",
      "I tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 2636 get requests, put_count=2560 evicted_count=1000 eviction_rate=0.390625 and unsatisfied allocation rate=0.446131\n",
      "I tensorflow/core/common_runtime/gpu/pool_allocator.cc:257] Raising pool_size_limit_ from 100 to 110\n",
      "step 3 - loss = 5.509998, (3.244 sec/step)\n",
      "step 4 - loss = 5.493878, (3.249 sec/step)\n",
      "step 5 - loss = 5.475053, (3.245 sec/step)\n",
      "step 6 - loss = 5.453598, (3.240 sec/step)\n",
      "step 7 - loss = 5.423910, (3.250 sec/step)\n",
      "step 8 - loss = 5.407636, (3.237 sec/step)\n",
      "step 9 - loss = 5.342577, (3.245 sec/step)\n",
      "...\n",

     ]
    }
   ],
   "source": [
    "# !python train.py --data_dir=corpus --restore_from=./logdir/train/2016-12-14T20-24-30 \n",
    "!python train.py --data_dir=corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Generaci√≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!python generate.py --wav_out_path=generated.wav --samples 56000 model.ckpt-99999"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
